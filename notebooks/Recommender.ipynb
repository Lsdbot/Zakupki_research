{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab84efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, \\\n",
    "                            recall_score, f1_score, log_loss\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "from typing import Tuple, Set\n",
    "\n",
    "import yaml\n",
    "\n",
    "import joblib\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_purchases(string):\n",
    "    return list(map(int, re.findall(r\"'(\\d+)'\", string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fae6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vector(string):\n",
    "    return list(map(float, string[1:-1].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd76035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name = \"Default\"):\n",
    "    \"\"\"Метрики для задачи классификации\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "    df_metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    try:\n",
    "        df_metrics['ROC_AUC'] = roc_auc_score(y_test, y_score[:, 1])\n",
    "        df_metrics['Precision'] = precision_score(y_test, y_pred, zero_division=0)\n",
    "        df_metrics['Recall'] = recall_score(y_test, y_pred, zero_division=0)\n",
    "        df_metrics['f1'] = f1_score(y_test, y_pred, zero_division=0)\n",
    "        df_metrics['Logloss'] = log_loss(y_test, y_score)\n",
    "        \n",
    "    except ValueError:\n",
    "        df_metrics['ROC_AUC'] = 0\n",
    "        df_metrics['Precision'] = 0\n",
    "        df_metrics['Recall'] = 0\n",
    "        df_metrics['f1'] = 0\n",
    "        df_metrics['Logloss'] = 0\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010e514",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "def save_file(file_path, data):       \n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../config/params.yaml\"\n",
    "config = yaml.load(open(config_path), Loader=yaml.FullLoader)\n",
    "\n",
    "preproc = config[\"preprocessing\"]\n",
    "train = config[\"train\"]['recommender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_params = open_file(train['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2e382",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e44288",
   "metadata": {},
   "source": [
    "В данном блоке мы строим и обучаем рекомендательные систему. Также подбираем параметры для моделей с помощью байесовского оптимизатора.  \n",
    "\n",
    "Результатом этого блока являются файл с моделью на каждого поставщика, лучшими параметрами и метриками качества моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe52ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(preproc['train_data'])\n",
    "df_train = df_train.set_index('index')\n",
    "\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d8812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(preproc['test_data'])\n",
    "df_test = df_test.set_index('index')\n",
    "\n",
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(preproc['recommend_sub_path'])\n",
    "df_submission = df_submission.set_index('index')\n",
    "\n",
    "df_submission[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_submission['purchases'].apply(extract_purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45625e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация признаков на основе вектора токенов\n",
    "df_train['vectorized'] = df_train['vectorized'].apply(extract_vector)\n",
    "df_test['vectorized'] = df_test['vectorized'].apply(extract_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1856eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование типов столбцов\n",
    "df_train = df_train.astype(preproc['change_type_columns'])\n",
    "df_test = df_test.astype(preproc['change_type_columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8483a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Преобрауем вектор в признаки объекта\n",
    "for i in tqdm(range(100)):\n",
    "    df_train[str(i)] = df_train['vectorized'].apply(lambda x: x[i])\n",
    "    df_test[str(i)] = df_test['vectorized'].apply(lambda x: x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f2807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb57371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd25e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отсортируем по длине массива\n",
    "df_submission = df_submission.reindex(df_submission.apply(len).sort_values(\n",
    "    ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supplier_data(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "                  sup: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Filters train and test DataFrames based on the unique reg_code of a given supplier.\n",
    "    Removes unnecessary columns and duplicates.\n",
    "    Drops purchases that exist in both train and test DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_train: pd.DataFrame\n",
    "    The train DataFrame\n",
    "    df_test: pd.DataFrame\n",
    "    The test DataFrame\n",
    "    sup: str\n",
    "    The name of the supplier to filter the DataFrames by\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "    A tuple of filtered DataFrames for train and test, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    unique_reg_okpd = df_train[df_train['supplier'] == sup]['reg_code'].unique()\n",
    "    \n",
    "    # фильтруем train и test на основе уникальных reg_code поставщиков \n",
    "    df_sup_train = df_train[df_train['reg_code'].isin(unique_reg_okpd)]\n",
    "    df_sup_test = df_test[df_test['reg_code'].isin(unique_reg_okpd)]\n",
    "\n",
    "    \n",
    "    if df_sup_test.empty:\n",
    "        df_sup_test = df_test\n",
    "    \n",
    "    # удаляем ненужные для системы рекомендаций стобцы и дубликаты\n",
    "    df_sup_train = df_sup_train.drop(columns=train['drop_columns']).drop_duplicates()\n",
    "    df_sup_test = df_sup_test.drop(columns=train['drop_columns']).drop_duplicates()\n",
    "    \n",
    "\n",
    "    df_sup_test = df_sup_test.set_index('purchase')\n",
    "    df_sup_train = df_sup_train.set_index('purchase')\n",
    "    \n",
    "    # удаляем закупки, которые есть и test, и в train\n",
    "    df_sup_train = df_sup_train.drop(set(df_submission[sup]).intersection(df_sup_train.index))\n",
    "    df_sup_test = df_sup_test[~df_sup_test.index.isin(df_sup_train.index)]\n",
    "    \n",
    "    \n",
    "    return df_sup_train, df_sup_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f6841",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_lgbm(df_tr: pd.DataFrame, df_t: pd.DataFrame, sup, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains a LightGBM classifier on the training set and returns the score on the test set.\n",
    "\n",
    "    Args:\n",
    "        df_tr (pandas.DataFrame): A pandas DataFrame containing the training set.\n",
    "        df_t (pandas.DataFrame): A pandas DataFrame containing the test set.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The score on the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x_train = df_tr[df_tr.columns[:-1]]\n",
    "    y_train = df_tr['target']\n",
    "    \n",
    "    x_test = df_t[df_tr.columns[:-1]]\n",
    "    y_test = df_t['target']\n",
    "    \n",
    "\n",
    "    model = LGBMClassifier(class_weight='balanced', \n",
    "                           n_jobs=-1, \n",
    "                           **kwargs)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_score = model.predict_proba(x_test)\n",
    "    \n",
    "\n",
    "    return get_metrics(y_test, y_pred, y_score, name=sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad024a29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_metrics = pd.DataFrame()\n",
    "\n",
    "for sup in tqdm(df_submission.index[:100]):\n",
    "    \n",
    "    # выделяем train и test для поставщика\n",
    "    df_sup_train, df_sup_test = supplier_data(df_train, df_test, sup)\n",
    "\n",
    "    \n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(df_train[df_train['supplier'] == sup]['purchase']\n",
    "                                                     .unique()).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_submission[sup]).astype(int)\n",
    "\n",
    "    \n",
    "    metric = train_lgbm(df_sup_train, df_sup_test, sup, random_state=train['random_state'])\n",
    "    \n",
    "    \n",
    "    base_metrics = pd.concat([base_metrics, metric], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d408638",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_metrics = base_metrics.set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20585b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_metrics.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_metrics['basic_metrics'] = base_metrics.mean().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b83c8",
   "metadata": {},
   "source": [
    "# Tune params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, x: pd.DataFrame, y: pd.Series, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    This function defines the objective function for an Optuna study to tune hyperparameters\n",
    "    for a LightGBM binary classification model. \n",
    "\n",
    "    Args:\n",
    "        trial (optuna.Trial): A trial corresponding to a set of hyperparameters.\n",
    "        x (pd.DataFrame): The features to be used for training and validation.\n",
    "        y (pd.Series): The target variable for training and validation.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean of the cross-validation AUC-ROC scores for the given set of hyperparameters.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [400]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 5),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [kwargs['learning_rate']]),\n",
    "        'max_bin': trial.suggest_int('max_bin', 10, 120, step=10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 500, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 100, 5000, step=100),\n",
    "        'lambda_l1': trial.suggest_int('lambda_l1', 0, 100),\n",
    "        'lambda_l2': trial.suggest_int('lambda_l2', 0, 100),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 0.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.3, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 2, 6),\n",
    "        'extra_trees': trial.suggest_categorical('extra_trees', [True, False]),\n",
    "        'objective':'binary',\n",
    "        'metric': 'auc',\n",
    "        'random_state': train['random_state'],\n",
    "    }\n",
    "\n",
    "    cv_pred = np.empty(train['N_FOLDS'])\n",
    "    cv = StratifiedKFold(n_splits=train['N_FOLDS'], shuffle=True, random_state=train['random_state'])\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(x, y)):\n",
    "        x_train_, x_val_ = x.iloc[train_idx], x.iloc[test_idx]\n",
    "        y_train_, y_val_ = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        pruning = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "\n",
    "        model = LGBMClassifier(\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            **params\n",
    "        )\n",
    "        model.fit(x_train_, y_train_,\n",
    "                  eval_metric='auc',\n",
    "                  eval_set=[(x_val_, y_val_)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  callbacks=[pruning],\n",
    "                  verbose=-1)\n",
    "\n",
    "        y_pred = model.predict(x_val_)\n",
    "        y_proba = model.predict_proba(x_val_)[:, 1]\n",
    "\n",
    "        cv_pred[fold] = roc_auc_score(y_val_, y_proba)\n",
    "        \n",
    "    return (np.mean(cv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d128fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(df_train: pd.DataFrame, df_test: pd.DataFrame, \n",
    "               df_submission: pd.DataFrame, sup, **kwargs) -> pd.DataFrame:\n",
    "    \n",
    "    # определяем train и test для поставщика\n",
    "    df_sup_train, df_sup_test = supplier_data(df_train, df_test, sup)\n",
    "    \n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(df_train[df_train['supplier'] == sup]['purchase']\n",
    "                                                     .unique()).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_submission[sup]).astype(int)\n",
    "    \n",
    "    # добавляем метки класса\n",
    "    x_train = df_sup_train[df_sup_train.columns[:-1]]\n",
    "    y_train = df_sup_train['target']\n",
    "        \n",
    "    func = lambda trial: objective(trial, x_train, y_train, **kwargs)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(func, n_trials=50, n_jobs=-1)\n",
    "        \n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1091f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sup in tqdm(df_submission.index[:100]):\n",
    "    \n",
    "    recommender_params[sup] = tune_model(df_train, df_test, df_submission, \n",
    "                                         sup, random_state=train['random_state'],\n",
    "                                         learning_rate=recommender_params[sup]['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(train['params'], recommender_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e06cf2",
   "metadata": {},
   "source": [
    "# Best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e0c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "for sup in tqdm(df_submission.index[:100]):\n",
    "\n",
    "    # определяем датасеты для поставщика\n",
    "    df_sup_train, df_sup_test = supplier_data(df_train, df_test, sup)\n",
    "\n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(\n",
    "        df_train[df_train['supplier'] == sup]['purchase'].unique()).astype(int)\n",
    "    df_sup_test['target'] = df_sup_test.index.isin(df_submission[sup]).astype(int)\n",
    "\n",
    "    \n",
    "    metrics = pd.concat([metrics, train_lgbm(df_sup_train, df_sup_test, sup, \n",
    "                                             **recommender_params[sup])], ignore_index=True)\n",
    "    \n",
    "metrics.set_index('model', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab600c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d27299",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_metrics['best_metrics'] = np.mean(metrics).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea62ab",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Сохранение метрик\n",
    "with open(train['metrics'], 'w') as file:\n",
    "    yaml.dump(recommender_metrics, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee998f15",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sup in tqdm(df_submission.index[:100]):\n",
    "\n",
    "    # определяем датасеты для поставщика\n",
    "    df_sup_train, df_sup_test = supplier_data(df_train, df_test, sup)\n",
    "\n",
    "    # добавляем метки для обучения алгоритма классификации \n",
    "    df_sup_train['target'] = df_sup_train.index.isin(\n",
    "        df_train[df_train['supplier'] == sup]['purchase'].unique()).astype(int)\n",
    "\n",
    "    x_train = df_sup_train[df_sup_train.columns[:-1]]\n",
    "    y_train = df_sup_train['target']\n",
    "    \n",
    "\n",
    "    model = LGBMClassifier(class_weight='balanced', n_jobs=-1, \n",
    "                           **recommender_params[sup])\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    models[sup] = model\n",
    "    \n",
    "joblib.dump(models, train['models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca96e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
